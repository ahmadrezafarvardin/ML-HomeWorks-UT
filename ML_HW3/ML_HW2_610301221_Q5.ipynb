{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e98900f",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5b0c5",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "**Step 1:** Load the Dataset into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3544c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_links</th>\n",
       "      <th>num_unique_domains</th>\n",
       "      <th>num_email_addresses</th>\n",
       "      <th>num_spelling_errors</th>\n",
       "      <th>num_urgent_keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  num_unique_words  num_stopwords  num_links  num_unique_domains  \\\n",
       "0        140                94             52          0                   0   \n",
       "1          5                 5              1          0                   0   \n",
       "2         34                32             15          0                   0   \n",
       "3          6                 6              2          0                   0   \n",
       "4          9                 9              2          0                   0   \n",
       "\n",
       "   num_email_addresses  num_spelling_errors  num_urgent_keywords  label  \n",
       "0                    0                    0                    0      0  \n",
       "1                    0                    0                    0      0  \n",
       "2                    0                    0                    0      0  \n",
       "3                    0                    0                    0      0  \n",
       "4                    0                    0                    0      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"email_phishing_data.csv\")\n",
    "\n",
    "# Display the first 5 rows to inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fde1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_links</th>\n",
       "      <th>num_unique_domains</th>\n",
       "      <th>num_email_addresses</th>\n",
       "      <th>num_spelling_errors</th>\n",
       "      <th>num_urgent_keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.248460e+05</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "      <td>524846.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.762280e+02</td>\n",
       "      <td>123.012167</td>\n",
       "      <td>80.045465</td>\n",
       "      <td>0.895588</td>\n",
       "      <td>0.347767</td>\n",
       "      <td>2.114897</td>\n",
       "      <td>24.694731</td>\n",
       "      <td>0.245301</td>\n",
       "      <td>0.013240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.335457e+03</td>\n",
       "      <td>201.626478</td>\n",
       "      <td>1023.330380</td>\n",
       "      <td>5.603001</td>\n",
       "      <td>1.774209</td>\n",
       "      <td>13.592682</td>\n",
       "      <td>311.312358</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>0.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.690000e+02</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.339682e+06</td>\n",
       "      <td>51251.000000</td>\n",
       "      <td>720411.000000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>190104.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_words  num_unique_words  num_stopwords      num_links  \\\n",
       "count  5.248460e+05     524846.000000  524846.000000  524846.000000   \n",
       "mean   2.762280e+02        123.012167      80.045465       0.895588   \n",
       "std    3.335457e+03        201.626478    1023.330380       5.603001   \n",
       "min    0.000000e+00          0.000000       0.000000       0.000000   \n",
       "25%    4.700000e+01         38.000000      12.000000       0.000000   \n",
       "50%    1.200000e+02         79.000000      34.000000       0.000000   \n",
       "75%    2.690000e+02        145.000000      79.000000       0.000000   \n",
       "max    2.339682e+06      51251.000000  720411.000000     824.000000   \n",
       "\n",
       "       num_unique_domains  num_email_addresses  num_spelling_errors  \\\n",
       "count       524846.000000        524846.000000        524846.000000   \n",
       "mean             0.347767             2.114897            24.694731   \n",
       "std              1.774209            13.592682           311.312358   \n",
       "min              0.000000             0.000000             0.000000   \n",
       "25%              0.000000             0.000000             2.000000   \n",
       "50%              0.000000             0.000000             8.000000   \n",
       "75%              0.000000             1.000000            22.000000   \n",
       "max            524.000000          1150.000000        190104.000000   \n",
       "\n",
       "       num_urgent_keywords          label  \n",
       "count        524846.000000  524846.000000  \n",
       "mean              0.245301       0.013240  \n",
       "std               0.559320       0.114301  \n",
       "min               0.000000       0.000000  \n",
       "25%               0.000000       0.000000  \n",
       "50%               0.000000       0.000000  \n",
       "75%               0.000000       0.000000  \n",
       "max               7.000000       1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef5943d",
   "metadata": {},
   "source": [
    "**Step 2:** Split Data into 80% Train and 20% Test with Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f947ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " label\n",
      "0    0.98676\n",
      "1    0.01324\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test class distribution:\n",
      " label\n",
      "0    0.986758\n",
      "1    0.013242\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df.drop(\"label\", axis=1)  # Replace \"label\" with your target column name\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split into train (80%) and test (20%) with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,  # Fixed random state for reproducibility\n",
    "    stratify=y       # Ensures equal class distribution in train/test\n",
    ")\n",
    "\n",
    "# Verify class distribution\n",
    "print(\"Train class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest class distribution:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7498e",
   "metadata": {},
   "source": [
    "## Part 2:\n",
    "Implementing Logistic Regression on the Phishing Email Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc58d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the model\n",
    "# Increased max_iter for convergence\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679abfb6",
   "metadata": {},
   "source": [
    "## Part 3:\n",
    "Feature Selection with Sequential Forward Selection (SFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b51145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c82d3",
   "metadata": {},
   "source": [
    "**Step 1:** Initialize SFS for 3, 4, and 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac2e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFS for 2 features\n",
    "sfs_2 = SFS(logreg,\n",
    "            k_features=2,\n",
    "            forward=True,\n",
    "            scoring='accuracy',\n",
    "            cv=2,  # 2-fold cross-validation\n",
    "            n_jobs=-1)\n",
    "\n",
    "# SFS for 3 features\n",
    "sfs_3 = SFS(logreg,\n",
    "            k_features=3,\n",
    "            forward=True,\n",
    "            scoring='accuracy',\n",
    "            cv=2,  # 2-fold cross-validation\n",
    "            n_jobs=-1)\n",
    "\n",
    "# SFS for 4 features\n",
    "sfs_4 = SFS(logreg,\n",
    "            k_features=4,\n",
    "            forward=True,\n",
    "            scoring='accuracy',\n",
    "            cv=2,\n",
    "            n_jobs=-1)\n",
    "\n",
    "# SFS for 5 features\n",
    "sfs_5 = SFS(logreg,\n",
    "            k_features=5,\n",
    "            forward=True,\n",
    "            scoring='accuracy',\n",
    "            cv=2,\n",
    "            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0ab8a",
   "metadata": {},
   "source": [
    "**Step 3:** Fit SFS and Report Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d0529cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Features: ['num_words', 'num_unique_domains']\n",
      "Top 3 Features: ['num_words', 'num_unique_domains', 'num_spelling_errors']\n",
      "Top 4 Features: ['num_words', 'num_unique_words', 'num_unique_domains', 'num_spelling_errors']\n",
      "Top 5 Features: ['num_words', 'num_unique_words', 'num_unique_domains', 'num_email_addresses', 'num_spelling_errors']\n"
     ]
    }
   ],
   "source": [
    "# Fit SFS to training data\n",
    "sfs_2.fit(X_train, y_train)\n",
    "sfs_3.fit(X_train, y_train)\n",
    "sfs_4.fit(X_train, y_train)\n",
    "sfs_5.fit(X_train, y_train)\n",
    "\n",
    "# Get selected feature names\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Print results\n",
    "print(\"Top 2 Features:\", [feature_names[i] for i in sfs_2.k_feature_idx_])\n",
    "print(\"Top 3 Features:\", [feature_names[i] for i in sfs_3.k_feature_idx_])\n",
    "print(\"Top 4 Features:\", [feature_names[i] for i in sfs_4.k_feature_idx_])\n",
    "print(\"Top 5 Features:\", [feature_names[i] for i in sfs_5.k_feature_idx_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae7d43",
   "metadata": {},
   "source": [
    "## Part 4:\n",
    "Implementing Custom Sequential Forward Selection (SFS) from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5c331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "class CustomSFS:\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score, cv=2):\n",
    "        self.estimator = estimator\n",
    "        self.k_features = k_features\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "        self.selected_features = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feature_set = set(range(X.shape[1]))\n",
    "        self.selected_features = []\n",
    "\n",
    "        for _ in range(self.k_features):\n",
    "            best_score = -np.inf\n",
    "            best_feature = None\n",
    "\n",
    "            # Evaluate each candidate feature\n",
    "            for feature in feature_set:\n",
    "                current_features = self.selected_features + [feature]\n",
    "                X_subset = X.iloc[:, current_features]\n",
    "\n",
    "                # Cross-validation\n",
    "                scores = cross_val_score(\n",
    "                    self.estimator, X_subset, y,\n",
    "                    scoring='accuracy', cv=self.cv, n_jobs=-1\n",
    "                )\n",
    "                mean_score = np.mean(scores)\n",
    "\n",
    "                if mean_score > best_score:\n",
    "                    best_score = mean_score\n",
    "                    best_feature = feature\n",
    "\n",
    "            # Add the best feature to selected features\n",
    "            self.selected_features.append(best_feature)\n",
    "            feature_set.remove(best_feature)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_k_features(self):\n",
    "        return self.selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e5cfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomSFS Top 2 Features: ['num_words', 'num_unique_domains']\n",
      "CustomSFS Top 3 Features: ['num_words', 'num_unique_domains', 'num_spelling_errors']\n",
      "CustomSFS Top 4 Features: ['num_words', 'num_unique_domains', 'num_spelling_errors', 'num_unique_words']\n",
      "CustomSFS Top 5 Features: ['num_words', 'num_unique_domains', 'num_spelling_errors', 'num_unique_words', 'num_email_addresses']\n"
     ]
    }
   ],
   "source": [
    "# Initialize CustomSFS\n",
    "custom_sfs_2 = CustomSFS(\n",
    "    estimator=LogisticRegression(\n",
    "        max_iter=1000, random_state=42),\n",
    "    k_features=2,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "custom_sfs_3 = CustomSFS(\n",
    "    estimator=LogisticRegression(\n",
    "        max_iter=1000, random_state=42),\n",
    "    k_features=3,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "custom_sfs_4 = CustomSFS(\n",
    "    estimator=LogisticRegression(\n",
    "        max_iter=1000, random_state=42),\n",
    "    k_features=4,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "custom_sfs_5 = CustomSFS(\n",
    "    estimator=LogisticRegression(\n",
    "        max_iter=1000, random_state=42),\n",
    "    k_features=5,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "# Fit to data\n",
    "custom_sfs_2.fit(X_train, y_train)\n",
    "custom_sfs_3.fit(X_train, y_train)\n",
    "custom_sfs_4.fit(X_train, y_train)\n",
    "custom_sfs_5.fit(X_train, y_train)\n",
    "\n",
    "# Get selected features\n",
    "custom_features_2 = [X_train.columns[i] for i in custom_sfs_2.get_k_features()]\n",
    "custom_features_3 = [X_train.columns[i] for i in custom_sfs_3.get_k_features()]\n",
    "custom_features_4 = [X_train.columns[i] for i in custom_sfs_4.get_k_features()]\n",
    "custom_features_5 = [X_train.columns[i] for i in custom_sfs_5.get_k_features()]\n",
    "\n",
    "print(\"CustomSFS Top 2 Features:\", custom_features_2)\n",
    "print(\"CustomSFS Top 3 Features:\", custom_features_3)\n",
    "print(\"CustomSFS Top 4 Features:\", custom_features_4)\n",
    "print(\"CustomSFS Top 5 Features:\", custom_features_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12956cb3",
   "metadata": {},
   "source": [
    "**Validation That Results Are Equivalent:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feccde00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sets of selected features are identical\n",
    "mlxtend_features_5 = [feature_names[i] for i in sfs_5.k_feature_idx_]\n",
    "set(custom_features_5) == set(mlxtend_features_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61a6930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Accuracy: 0.9868, mlxtend Accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "# Check if both feature sets give same accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train on custom features\n",
    "logreg.fit(X_train[custom_features_5], y_train)\n",
    "custom_acc = accuracy_score(y_test, logreg.predict(X_test[custom_features_5]))\n",
    "\n",
    "# Train on mlxtend features (same features, different order)\n",
    "logreg.fit(X_train[mlxtend_features_5], y_train)\n",
    "mlxtend_acc = accuracy_score(y_test, logreg.predict(X_test[mlxtend_features_5]))\n",
    "\n",
    "print(f\"Custom Accuracy: {custom_acc:.4f}, mlxtend Accuracy: {mlxtend_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2b67a",
   "metadata": {},
   "source": [
    "### **Phishing Email Detection - Feature Selection Report**  \n",
    "\n",
    "#### **1. Objective**  \n",
    "Implement **Sequential Forward Selection (SFS)** to identify the most discriminative features for detecting phishing emails using Logistic Regression.  \n",
    "\n",
    "#### **2. Methodology**  \n",
    "- **Dataset**: Phishing email data with features like `num_words`, `num_unique_domains`, `num_spelling_errors`, etc.  \n",
    "- **Approach**:  \n",
    "  - Used **mlxtend’s SFS** and a **custom SFS implementation** to select top `k` features.  \n",
    "  - Evaluated feature subsets using **2-fold cross-validation** with Logistic Regression.  \n",
    "  - Compared results between both implementations.  \n",
    "\n",
    "#### **3. Key Findings**  \n",
    "##### **Selected Features (Identical in Both Implementations)**  \n",
    "| Features Selected | Top 2 | Top 3 | Top 4 | Top 5 |\n",
    "|------------------|-------|-------|-------|-------|\n",
    "| **CustomSFS** | `num_words`, `num_unique_domains` | + `num_spelling_errors` | + `num_unique_words` | + `num_email_addresses` |\n",
    "| **mlxtend SFS** | `num_words`, `num_unique_domains` | + `num_spelling_errors` | + `num_unique_words` | + `num_email_addresses` |\n",
    "\n",
    "- **Consistency**: Both methods selected the **same features**, differing only in **minor ordering** (no impact on model performance).  \n",
    "- **Performance**:  \n",
    "  - **Accuracy (Top 5 Features)**: **0.9868** (same for both implementations).  \n",
    "  - **Most Important Features**:  \n",
    "    1. `num_words` (email length is a strong phishing indicator)  \n",
    "    2. `num_unique_domains` (multiple suspicious domains → phishing)  \n",
    "    3. `num_spelling_errors` (common in scam emails)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d9e85",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
